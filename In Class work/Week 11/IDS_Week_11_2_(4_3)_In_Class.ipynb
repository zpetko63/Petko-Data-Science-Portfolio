{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **K-Nearest Neighbors (KNN) Classification on the Titanic Dataset**\n",
        "\n",
        "In this notebook, we'll walk through performing k‑nearest neighbors (KNN) classification using the Titanic dataset. We will follow these steps:\n",
        "\n",
        "1. **Load and Inspect the Data:** Import and examine the dataset.\n",
        "2. **Preprocess the Data:** Handle missing values and encode categorical variables.\n",
        "3. **Split the Data:** Divide the dataset into training and testing sets.\n",
        "4. **Evaluate KNN Without Scaling:** Train and evaluate the KNN model on the original (unscaled) data.\n",
        "5. **Scale the Data:** Apply feature scaling.\n",
        "6. **Evaluate KNN With Scaling:** Re-run the model using the scaled data to see the improvement.\n",
        "7. **Explore the Effect of Different k Values:** Analyze how varying the number of neighbors affects performance."
      ],
      "metadata": {
        "id": "wx--DTP5WMWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load and Inspect the Data\n",
        "\n",
        "We begin by importing the necessary libraries and loading the Titanic dataset using seaborn. This lets us inspect the dataset structure and identify any issues before modeling."
      ],
      "metadata": {
        "id": "4leK_Zf2VdOK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-6NpqMQUuxx"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Titanic dataset from seaborn\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Display the first five rows of the dataset\n",
        "print(\"First five rows of the Titanic dataset:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Preprocess the Data\n",
        "\n",
        "Before training our model, we need to clean and prepare the dataset:\n",
        "- **Handling Missing Values:** Remove rows with missing 'age' values so that the model is trained on complete data.\n",
        "- **Encoding Categorical Variables:** Convert categorical variables like 'sex' into numerical values using one-hot encoding (dropping the first category to avoid multicollinearity).\n",
        "\n",
        "Finally, we define our feature set and the target variable."
      ],
      "metadata": {
        "id": "_Jt4c9zNVhyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with missing 'age' values to ensure a clean dataset\n",
        "df.dropna(subset=['age'], inplace=True)\n",
        "\n",
        "# Encode the 'sex' column into a numeric format using one-hot encoding.\n",
        "# The drop_first parameter is set to True to avoid multicollinearity.\n",
        "df = pd.get_dummies(df, columns=['sex'], drop_first=True)\n",
        "\n",
        "# Define the features and target variable\n",
        "features = ['pclass', 'age', 'sibsp', 'parch', 'fare', 'sex_male']\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# Preview the cleaned features and target\n",
        "print(\"Features preview:\")\n",
        "print(X.head())\n",
        "print(\"\\nTarget preview:\")\n",
        "print(y.head())"
      ],
      "metadata": {
        "id": "YIMV82_qVkct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Split the Data\n",
        "\n",
        "We split the dataset into training and testing subsets:\n",
        "- **Training Set (80%):** Used to fit the k‑nearest neighbors model.\n",
        "- **Testing Set (20%):** Used to evaluate the model’s performance.\n",
        "\n",
        "A random state is set to ensure reproducibility."
      ],
      "metadata": {
        "id": "6lXHX3PsVgND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset: 80% for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "5xPl64sQVnYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Train the K-Nearest Neighbors Model\n",
        "\n",
        "KNN is a non‑parametric, instance-based learning algorithm. It classifies a new data point by:\n",
        "- Calculating the distance between the new data point and all points in the training set.\n",
        "- Identifying the 'k' nearest neighbors.\n",
        "- Assigning the class that is most common among these neighbors.\n",
        "\n",
        "In this example, we initialize our KNN classifier with `k=5` (i.e., considering the 5 nearest neighbors) and train it using the training data."
      ],
      "metadata": {
        "id": "G2ED5Ql9Vp61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the KNN classifier with k=5 neighbors\n",
        "\n",
        "# Train the model using the training data\n"
      ],
      "metadata": {
        "id": "QVvY832OVq7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Evaluate the Model\n",
        "\n",
        "To assess the performance of our KNN model, we will use the following metrics:\n",
        "- **Accuracy:** The overall proportion of correct predictions.\n",
        "- **Confusion Matrix:** A table that compares the actual labels with those predicted by the model.\n",
        "- **Classification Report:** Provides precision, recall, and F1-score for each class.\n",
        "\n",
        "We begin by predicting the labels for the test data and then compute these evaluation metrics."
      ],
      "metadata": {
        "id": "hKz3fIVfVtiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Predict the labels for the test dataset\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with k=5: {accuracy:.2f}\")\n",
        "\n",
        "# Generate the confusion matrix and display it using a heatmap\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('KNN Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Print the classification report with detailed metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "ECBT3rfWVuhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Scale the Data\n",
        "\n",
        "Since KNN is sensitive to the scale of the features, scaling can often lead to a substantial improvement in performance. Here, we use the StandardScaler to:\n",
        "- Standardize the features so that they have a mean of 0 and a standard deviation of 1.\n",
        "- Apply the transformation to both the training and testing data (using the training data to fit the scaler to avoid data leakage).\n",
        "\n",
        "After scaling, we will re-run the KNN model."
      ],
      "metadata": {
        "id": "vsatgP5vY3MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform both training and test data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Optional: Convert the scaled training data back to a DataFrame for inspection\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=features, index=X_train.index)\n",
        "print(\"Scaled training features preview:\")\n",
        "print(X_train_scaled_df.head())"
      ],
      "metadata": {
        "id": "jE6d2jtHY26X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Evaluate KNN With Scaling\n",
        "\n",
        "Now that we have scaled the features, we re-run the KNN model on the scaled data. We will use the same settings (k=5) to see how scaling affects the performance:\n",
        "- Training the model on the scaled training set.\n",
        "- Evaluating on the scaled test set with accuracy, confusion matrix, and a classification report."
      ],
      "metadata": {
        "id": "BnGDw4hNV47H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the KNN classifier with k=5 neighbors on the scaled data\n",
        "knn_scaled = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict the labels for the scaled test data\n",
        "y_pred_scaled = knn_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Calculate and print the accuracy for the scaled data\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Accuracy with scaling (k=5): {accuracy_scaled:.2f}\")\n",
        "\n",
        "# Generate and display the confusion matrix for the scaled data using a heatmap\n",
        "cm_scaled = confusion_matrix(y_test, y_pred_scaled)\n",
        "sns.heatmap(cm_scaled, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('KNN Confusion Matrix (Scaled Data)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Print the classification report for the scaled data\n",
        "print(\"\\nClassification Report (Scaled Data):\")\n",
        "print(classification_report(y_test, y_pred_scaled))"
      ],
      "metadata": {
        "id": "mn7eryjMZCYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Explore the Effect of Different k Values (Scaled Data)\n",
        "\n",
        "The performance of KNN can vary significantly with the choice of `k`. In this final step, we will:\n",
        "- Vary `k` from 1 to 20, odds only.\n",
        "- Train a KNN model for each `k` using the scaled data.\n",
        "- Plot the accuracy on the test set as a function of `k`.\n",
        "\n",
        "This analysis will help illustrate the impact of different neighborhood sizes on the model's performance when the data is scaled."
      ],
      "metadata": {
        "id": "oD31mE1RZFrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a range of k values to explore for all odd numbers\n",
        "\n",
        "\n",
        "# Loop through different values of k, train a KNN model on scaled data, and record the accuracy for each\n",
        "\n",
        "\n",
        "# Plot accuracy vs. number of neighbors (k) for the scaled data\n"
      ],
      "metadata": {
        "id": "ryWjO1qHV5zu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unsupervised Learning & PCA with Logistic Regression"
      ],
      "metadata": {
        "id": "-HTAFNtaHxXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates key concepts of unsupervised learning through Principal\n",
        "Component Analysis (PCA) and then compares the performance of a Logistic Regression\n",
        "classifier when trained on the original standardized data versus on the PCA–reduced data.\n",
        "\n",
        "In this notebook, we cover:\n",
        "\n",
        "1. **Overview of Unsupervised Learning & PCA**  \n",
        "   - We explain why unsupervised methods are used when there is no response variable.\n",
        "   - PCA is introduced as a method to reduce dimensionality by finding linear combinations\n",
        "     of the features that capture maximum variance.\n",
        "   - The mathematical ideas behind PCA are briefly discussed (centering, scaling, loadings, scores, and\n",
        "     the proportion of variance explained).\n",
        "\n",
        "2. **Data Preprocessing**  \n",
        "   - The Breast Cancer dataset is used as an example.\n",
        "   - The features are centered and scaled since PCA is sensitive to the scale of the variables.\n",
        "\n",
        "3. **PCA Computation and Visualization**  \n",
        "   - We compute PCA to reduce the data to two dimensions.\n",
        "   - A scatter plot of the principal component scores is generated.\n",
        "   - A biplot is created to visualize both the scores and the feature loadings.\n",
        "   - A scree plot is generated to display the cumulative proportion of variance explained.\n",
        "\n",
        "4. **Logistic Regression**  \n",
        "   - We split the dataset into training and testing sets.\n",
        "   - A Logistic Regression model is trained on both:\n",
        "       a) the original standardized features, and\n",
        "       b) the two-dimensional PCA–reduced features.\n",
        "   - The accuracy scores of both models are computed and printed for comparison.\n",
        "\n",
        "Let's begin by importing the necessary libraries and performing the analysis."
      ],
      "metadata": {
        "id": "1UTF4P2-H2Ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load and Preprocess the Data\n",
        "\n",
        "We begin by loading the Breast Cancer dataset.\n",
        "- The Breast Cancer dataset contains measurements for benign and malignant tumors.\n",
        "- Here, the dataset provides:\n",
        "    - `X` as a feature matrix\n",
        "    - `y` as a target variable"
      ],
      "metadata": {
        "id": "mv2jCW3SH6By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the Breast Cancer Wisconsin dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "X = breast_cancer.data  # Feature matrix\n",
        "y = breast_cancer.target  # Target variable (diagnosis)\n",
        "feature_names = breast_cancer.feature_names\n",
        "target_names = breast_cancer.target_names\n",
        "\n",
        "print(y)\n",
        "pd.DataFrame(X, columns = [feature_names])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "fIf3HAtbH6V7",
        "outputId": "f09778b9-fe6f-4581-d598-63d7c8810f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
              "0         17.99        10.38         122.80    1001.0         0.11840   \n",
              "1         20.57        17.77         132.90    1326.0         0.08474   \n",
              "2         19.69        21.25         130.00    1203.0         0.10960   \n",
              "3         11.42        20.38          77.58     386.1         0.14250   \n",
              "4         20.29        14.34         135.10    1297.0         0.10030   \n",
              "..          ...          ...            ...       ...             ...   \n",
              "564       21.56        22.39         142.00    1479.0         0.11100   \n",
              "565       20.13        28.25         131.20    1261.0         0.09780   \n",
              "566       16.60        28.08         108.30     858.1         0.08455   \n",
              "567       20.60        29.33         140.10    1265.0         0.11780   \n",
              "568        7.76        24.54          47.92     181.0         0.05263   \n",
              "\n",
              "    mean compactness mean concavity mean concave points mean symmetry  \\\n",
              "0            0.27760        0.30010             0.14710        0.2419   \n",
              "1            0.07864        0.08690             0.07017        0.1812   \n",
              "2            0.15990        0.19740             0.12790        0.2069   \n",
              "3            0.28390        0.24140             0.10520        0.2597   \n",
              "4            0.13280        0.19800             0.10430        0.1809   \n",
              "..               ...            ...                 ...           ...   \n",
              "564          0.11590        0.24390             0.13890        0.1726   \n",
              "565          0.10340        0.14400             0.09791        0.1752   \n",
              "566          0.10230        0.09251             0.05302        0.1590   \n",
              "567          0.27700        0.35140             0.15200        0.2397   \n",
              "568          0.04362        0.00000             0.00000        0.1587   \n",
              "\n",
              "    mean fractal dimension  ... worst radius worst texture worst perimeter  \\\n",
              "0                  0.07871  ...       25.380         17.33          184.60   \n",
              "1                  0.05667  ...       24.990         23.41          158.80   \n",
              "2                  0.05999  ...       23.570         25.53          152.50   \n",
              "3                  0.09744  ...       14.910         26.50           98.87   \n",
              "4                  0.05883  ...       22.540         16.67          152.20   \n",
              "..                     ...  ...          ...           ...             ...   \n",
              "564                0.05623  ...       25.450         26.40          166.10   \n",
              "565                0.05533  ...       23.690         38.25          155.00   \n",
              "566                0.05648  ...       18.980         34.12          126.70   \n",
              "567                0.07016  ...       25.740         39.42          184.60   \n",
              "568                0.05884  ...        9.456         30.37           59.16   \n",
              "\n",
              "    worst area worst smoothness worst compactness worst concavity  \\\n",
              "0       2019.0          0.16220           0.66560          0.7119   \n",
              "1       1956.0          0.12380           0.18660          0.2416   \n",
              "2       1709.0          0.14440           0.42450          0.4504   \n",
              "3        567.7          0.20980           0.86630          0.6869   \n",
              "4       1575.0          0.13740           0.20500          0.4000   \n",
              "..         ...              ...               ...             ...   \n",
              "564     2027.0          0.14100           0.21130          0.4107   \n",
              "565     1731.0          0.11660           0.19220          0.3215   \n",
              "566     1124.0          0.11390           0.30940          0.3403   \n",
              "567     1821.0          0.16500           0.86810          0.9387   \n",
              "568      268.6          0.08996           0.06444          0.0000   \n",
              "\n",
              "    worst concave points worst symmetry worst fractal dimension  \n",
              "0                 0.2654         0.4601                 0.11890  \n",
              "1                 0.1860         0.2750                 0.08902  \n",
              "2                 0.2430         0.3613                 0.08758  \n",
              "3                 0.2575         0.6638                 0.17300  \n",
              "4                 0.1625         0.2364                 0.07678  \n",
              "..                   ...            ...                     ...  \n",
              "564               0.2216         0.2060                 0.07115  \n",
              "565               0.1628         0.2572                 0.06637  \n",
              "566               0.1418         0.2218                 0.07820  \n",
              "567               0.2650         0.4087                 0.12400  \n",
              "568               0.0000         0.2871                 0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cf4863d-d38f-46f0-8e8b-1a5e93ed1c41\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cf4863d-d38f-46f0-8e8b-1a5e93ed1c41')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9cf4863d-d38f-46f0-8e8b-1a5e93ed1c41 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9cf4863d-d38f-46f0-8e8b-1a5e93ed1c41');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd1a84c4-8860-4cab-9704-573c8349f65e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd1a84c4-8860-4cab-9704-573c8349f65e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd1a84c4-8860-4cab-9704-573c8349f65e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since PCA is sensitive to the scale of the variables, we must center and scale\n",
        "the data.\n",
        "- Centering ensures that each feature has a mean of zero, and scaling\n",
        "ensures that each feature has unit variance.\n",
        "- This prevents features with larger\n",
        "numerical ranges from dominating the PCA results."
      ],
      "metadata": {
        "id": "hIk0LW21JMdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# It is important to center and scale the features since PCA is sensitive to the variable scales.\n",
        "scaler = StandardScaler()\n",
        "X_std = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "3D1i01ZjH7E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Compute PCA\n",
        "\n",
        "In this step, we compute Principal Component Analysis (PCA) on the standardized data.\n",
        "PCA seeks to find new axes (principal components) that maximize the variance of the data.\n",
        "Each principal component is a linear combination of the original features.\n",
        "\n",
        "**Key Points:**\n",
        "- **Dimensionality Reduction:**  \n",
        "  PCA reduces the dimensionality of the data while retaining as much of the variance as possible.\n",
        "- **How It Works:**  \n",
        "  The first principal component is the direction along which the data vary the most.\n",
        "  Subsequent components are chosen to be orthogonal (uncorrelated) to the previous ones and\n",
        "  capture the remaining variance.\n",
        "- **Why Two Components:**  \n",
        "  For visualization purposes, we reduce the data to 2 dimensions. This allows us to create 2D plots\n",
        "  that illustrate the distribution of data points and the influence of the original features.\n",
        "\n",
        "Below, we reduce the data to 2 components using the `PCA` class from scikit-learn and print the\n",
        "explained variance ratio, which tells us the proportion of total variance captured by each component."
      ],
      "metadata": {
        "id": "U9HBQUidH6-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# We reduce the data to 2 components for visualization and further analysis.\n",
        "\n",
        "\n",
        "# Display the Explained Variance Ratio (i.e., the proportion of variance explained by each component)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC9Yh2GcIrva",
        "outputId": "7382ad90-14e8-4643-fc4c-cfe25978948d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance Ratio: [0.44272026 0.18971182]\n",
            "Cumulative Explained Variance: [0.44272026 0.63243208]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Visualization of PCA Results\n",
        "Visualization is a key benefit of PCA. By projecting the data into 2 dimensions, we can:\n",
        "1. **Scatter Plot of PCA Scores:**  \n",
        "   Plot the data points in the new coordinate system defined by the first two principal components.\n",
        "   This helps us see how the observations are spread out and whether distinct groups exist.\n",
        "2. **Biplot:**  \n",
        "   Overlay the original feature vectors (loadings) on the scatter plot to interpret the direction and\n",
        "   contribution of each feature in the reduced space.\n",
        "3. **Scree Plot:**  \n",
        "   Plot the cumulative explained variance versus the number of components. This helps in deciding the\n",
        "   number of components needed to capture most of the variance in the data (often by looking for an “elbow”\n",
        "   in the plot).\n",
        "\n",
        "The detailed instructions and visualizations below will help you understand the PCA results."
      ],
      "metadata": {
        "id": "yrXtHn_-IzXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3a. Scatter Plot of PCA Scores\n",
        "plt.figure(figsize=(8, 6))\n",
        "colors = ['navy', 'darkorange']\n",
        "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
        "    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], color=color, alpha=0.7,\n",
        "                label=target_name, edgecolor='k', s=60)\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('PCA: 2D Projection of Breast Cancer Data')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z1XOZXFNI6nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Biplot: PCA Scores with Feature Loadings\n",
        "\n",
        "A biplot is a useful visualization that shows both the projected data points (scores) and\n",
        "the contribution of the original features (loadings). The loading vectors indicate the\n",
        "direction in which the original features contribute most to the variance captured by the\n",
        "principal components.\n",
        "\n",
        "- **Loadings:**  \n",
        "  The PCA loadings are stored in `pca.components_` and represent the coefficients of the linear\n",
        "  combinations that define each principal component.\n",
        "- **Visualization:**  \n",
        "  We scale the loading vectors for better visibility and overlay them as arrows on the scatter plot."
      ],
      "metadata": {
        "id": "2eGyOo-DJypa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3b. Biplot: Overlaying Feature Loadings on PCA Scatter Plot\n",
        "# Compute the loadings (each column of pca.components_ represents a principal component)\n",
        "loadings = pca.components_.T\n",
        "scaling_factor = 50.0  # Increased scaling factor by 5 times\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "# Plot the PCA scores as before\n",
        "for color, i, target_name in zip(colors, [0, 1], target_names):\n",
        "    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], color=color, alpha=0.7,\n",
        "                label=target_name, edgecolor='k', s=60)\n",
        "# Plot the loadings as arrows\n",
        "for i, feature in enumerate(feature_names):\n",
        "    plt.arrow(0, 0, scaling_factor * loadings[i, 0], scaling_factor * loadings[i, 1],\n",
        "              color='r', width=0.02, head_width=0.1)\n",
        "    plt.text(scaling_factor * loadings[i, 0] * 1.1, scaling_factor * loadings[i, 1] * 1.1,  # Adjusted text position\n",
        "             feature, color='r', ha='center', va='center')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('Biplot: PCA Scores and Loadings')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nCmmkqiHIzB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scree Plot: Cumulative Explained Variance\n",
        "\n",
        "The scree plot displays the cumulative proportion of variance explained by the principal components.\n",
        "It is a valuable tool for deciding how many components to retain for further analysis:\n",
        "- **Elbow Method:**  \n",
        "  Look for the \"elbow\" in the plot—beyond this point, additional components contribute only\n",
        "  marginal gains in explained variance.\n",
        "- **Interpretation:**  \n",
        "  In our case, reducing the Breast Cancer data to 2 components explains a significant portion of the variance,\n",
        "  which justifies our choice for visualization.\n",
        "\n",
        "Below, we compute PCA without specifying the number of components to generate the full cumulative\n",
        "explained variance plot."
      ],
      "metadata": {
        "id": "bhtw_Gf8J4ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3c. Scree Plot: Cumulative Explained Variance\n",
        "# This plot helps in determining how many components to retain (looking for the \"elbow\")\n",
        "pca_full = PCA(n_components = 15).fit(X_std)\n",
        "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, len(cumulative_variance)+1), cumulative_variance, marker='o')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('PCA Variance Explained')\n",
        "plt.xticks(range(1, len(cumulative_variance)+1))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_f6G2nmOJBGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3d. Bar Plot: Variance Explained by Each Component\n",
        "plt.figure(figsize=(8, 6))\n",
        "components = range(1, len(pca_full.explained_variance_ratio_) + 1)\n",
        "plt.bar(components, pca_full.explained_variance_ratio_, alpha=0.7, color='teal')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.ylabel('Variance Explained')\n",
        "plt.title('Variance Explained by Each Principal Component')\n",
        "plt.xticks(components)\n",
        "plt.grid(True, axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E0ahpHclktcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explained = pca_full.explained_variance_ratio_ * 100  # individual variance (%) per component\n",
        "components = np.arange(1, len(explained) + 1)\n",
        "cumulative = np.cumsum(explained)"
      ],
      "metadata": {
        "id": "Ec6WAmxInNEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Create the combined plot\n",
        "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Bar plot for individual variance explained\n",
        "bar_color = 'steelblue'\n",
        "ax1.bar(components, explained, color=bar_color, alpha=0.8, label='Individual Variance')\n",
        "ax1.set_xlabel('Principal Component')\n",
        "ax1.set_ylabel('Individual Variance Explained (%)', color=bar_color)\n",
        "ax1.tick_params(axis='y', labelcolor=bar_color)\n",
        "ax1.set_xticks(components)\n",
        "ax1.set_xticklabels([f\"PC{i}\" for i in components])\n",
        "\n",
        "# Add percentage labels on each bar\n",
        "for i, v in enumerate(explained):\n",
        "    ax1.text(components[i], v + 1, f\"{v:.1f}%\", ha='center', va='bottom', fontsize=10, color='black')\n",
        "\n",
        "# Create a second y-axis for cumulative variance explained\n",
        "ax2 = ax1.twinx()\n",
        "line_color = 'crimson'\n",
        "ax2.plot(components, cumulative, color=line_color, marker='o', label='Cumulative Variance')\n",
        "ax2.set_ylabel('Cumulative Variance Explained (%)', color=line_color)\n",
        "ax2.tick_params(axis='y', labelcolor=line_color)\n",
        "ax2.set_ylim(0, 100)\n",
        "\n",
        "# Remove grid lines\n",
        "ax1.grid(False)\n",
        "ax2.grid(False)\n",
        "\n",
        "# Combine legends from both axes and position the legend inside the plot (middle right)\n",
        "lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax1.legend(lines1 + lines2, labels1 + labels2, loc='center right', bbox_to_anchor=(0.85, 0.5))\n",
        "\n",
        "plt.title('PCA: Variance Explained', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_KvF7JMLmBqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RwT4HkUSH6zh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Logistic Regression Classification Comparison (In-Groups)\n",
        "\n",
        "Finally, we explore how the data representation affects supervised learning by comparing a Logistic Regression's performance on:\n",
        "- **The Original Standardized Data:**  \n",
        "  This is our baseline, using the full feature set.\n",
        "- **The PCA–Reduced Data:**  \n",
        "  Here, we use only the two principal components obtained from PCA.\n",
        "\n",
        "**Procedure:**\n",
        "1. Split the dataset (both the standardized and PCA–reduced versions) into training and test sets.\n",
        "2. Train a Logistic Regression on each version.\n",
        "3. Evaluate and compare their accuracy on the test data.\n",
        "\n",
        "This exercise shows how dimensionality reduction via PCA might simplify the model while still\n",
        "capturing most of the signal, though some loss in accuracy is possible."
      ],
      "metadata": {
        "id": "NPL8MykLJ8Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split the standardized (original) data into training and test sets\n",
        "\n",
        "# Split the PCA-reduced data into training and test sets (using the same random state)\n"
      ],
      "metadata": {
        "id": "u8_jgmgKH6sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4a. Logistic Regression on Original Data\n"
      ],
      "metadata": {
        "id": "WSHpW5DKJ_oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vSkJV1-Gjo7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4a. Logistic Regression on PCA Data\n"
      ],
      "metadata": {
        "id": "7Q6Eqfa2KCx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discussion\n",
        "\n",
        "- **PCA Visualization:**  \n",
        "  The scatter plot and biplot help us understand how the original high-dimensional data is\n",
        "  projected onto two principal components, and how each original feature contributes to these\n",
        "  components.\n",
        "\n",
        "- **Explained Variance & Scree Plot:**  \n",
        "  The explained variance ratios indicate the proportion of total variance captured by each\n",
        "  component. The scree plot shows the cumulative variance, guiding us in selecting the number\n",
        "  of components to retain.\n",
        "\n",
        "- **Classifier Comparison:**  \n",
        "  The Logistic Regression model is applied to both the original standardized data and the PCA–reduced\n",
        "  data. By comparing the accuracy scores, we can assess the impact of dimensionality reduction on\n",
        "  the classifier’s performance.\n",
        "\n",
        "This notebook not only reinforces the theory behind PCA but also demonstrates its practical applications,\n",
        "including how reduced representations can be used in downstream supervised learning tasks."
      ],
      "metadata": {
        "id": "s0w-A48RH6lA"
      }
    }
  ]
}
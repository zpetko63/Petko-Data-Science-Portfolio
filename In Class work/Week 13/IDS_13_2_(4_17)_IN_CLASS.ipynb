{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unsupervised Learning with Hierarchical Clustering  \n",
        "### What will we learn?\n",
        "* The intuition behind hierarchical (agglomerative) clustering and the Ward linkage.  \n",
        "* How to read a dendrogram and decide on an appropriate number of clusters.  \n",
        "* Practical data‑preprocessing steps (selecting numeric columns, scaling).  \n",
        "* Dimensionality reduction with PCA for 2‑D exploratory plots.  \n",
        "* Communicating cluster insights on a world map."
      ],
      "metadata": {
        "id": "-HTAFNtaHxXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 1: Loading the Country‑Level Indicator Data  \n",
        "We will use the *“Country‑data.csv”* file from Kaggle  \n",
        "(<https://www.kaggle.com/datasets/rohan0301/unsupervised-learning-on-country-data>).  \n",
        "Each row represents a country and each column an economic or health indicator (e.g., GDP per capita, child mortality).  "
      ],
      "metadata": {
        "id": "tEGfGetsSXhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"rohan0301/unsupervised-learning-on-country-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "jiUWHSK_JAYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Assuming your CSV file is named 'Country-data.csv'\n",
        "# and is located inside the downloaded directory\n",
        "file_path = os.path.join(path, 'Country-data.csv')\n",
        "\n",
        "# Now read the CSV file using the file_path\n",
        "data = pd.read_csv(file_path)\n",
        "data.head() # Print the first few rows of the DataFrame"
      ],
      "metadata": {
        "id": "iSFVVS_oJIc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 2: Feature Selection & Quick EDA\n",
        "* We keep only our features (e.g. everything but country names)."
      ],
      "metadata": {
        "id": "mv2jCW3SH6By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Optional sanity‑check visual\n"
      ],
      "metadata": {
        "id": "ECNEhuLHSu-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3: Standardize by Scaling\n",
        "- Hierarchical clustering uses Euclidean distance; indicators measured on different scales (GDP vs. fertility) would dominate the metric.  \n",
        "- We standardise to zero mean / unit variance using `StandardScaler`.  \n"
      ],
      "metadata": {
        "id": "zCR-y-pAU2mG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SCiANpULU-am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 5: Building the Hierarchical Tree\n",
        "* **Ward linkage** merges clusters that yield the *smallest* increase in total within‑cluster variance.  \n",
        "* The dendrogram gives us two insights:  \n",
        "  1. Similarity structure (who merges early).  \n",
        "  2. Reasonable cut heights (horizontal line) for k clusters.  \n",
        "We truncate to the last 30 merges to keep the plot readable.  "
      ],
      "metadata": {
        "id": "0MK5MY2uVDW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Standardize the numeric features (centering and scaling)\n"
      ],
      "metadata": {
        "id": "fIf3HAtbH6V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 6: Choosing k & Assigning Clusters\n",
        "After visually inspecting the dendrogram we select **k=3** (feel free to experiment).  \n",
        "Agglomerative clustering with the same linkage method produces integer labels we can append to the dataframe.  \n"
      ],
      "metadata": {
        "id": "AHspX8ObaECi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select k and assigning cluster label with fit_predict()\n"
      ],
      "metadata": {
        "id": "3D1i01ZjH7E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 7: Low‑Dimensional Insight with PCA\n",
        "**Note:** PCA is *only* for display; it was **not** used to fit the clusters.  "
      ],
      "metadata": {
        "id": "sWxUfMVUapEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Visualize the Clustering Results Using PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reduce the dimensions for visualization (2D scatter plot)\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_std)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='viridis', s=60, edgecolor='k', alpha=0.7)\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('Agglomerative Clustering on Country Data (via PCA)')\n",
        "plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UC9Yh2GcIrva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 8: Putting Clusters on the Map  \n",
        "Choropleth maps make the result tangible for non‑technical audiences.  \n",
        "Plotly Express offers an immediate interactive world map keyed by **country name**.  "
      ],
      "metadata": {
        "id": "ESJSzB3La6jR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Define a discrete color mapping for the clusters (adjust colors as needed)\n",
        "color_map = {0:\"blue\", 1:\"orange\", 2:\"green\", 3:\"red\"}  # add more if k>4\n",
        "\n",
        "\n",
        "# Create the choropleth map\n",
        "fig = px.choropleth(\n",
        "    data[['country', 'Cluster']],\n",
        "    locationmode='country names',\n",
        "    locations='country',\n",
        "    title='Country Clusters on World Map',\n",
        "    color='Cluster',\n",
        "    color_discrete_map=color_map\n",
        ")\n",
        "\n",
        "# Update the geographic layout and legend settings\n",
        "fig.update_geos(fitbounds=\"locations\", visible=True)\n",
        "fig.update_layout(\n",
        "    legend_title_text='Cluster',\n",
        "    legend_title_side='top'\n",
        ")\n",
        "\n",
        "fig.show(engine='kaleido')"
      ],
      "metadata": {
        "id": "sLMiebWyJ-LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zF32HvMDl_Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- OPTIMAL k: Silhouette Elbow ----------------------------------------\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Range of candidate cluster counts\n",
        "k_range = range(2, 11)     # try 2–10 clusters; adjust as you like\n",
        "sil_scores = []\n",
        "\n",
        "for k in k_range:\n",
        "    # Fit hierarchical clustering with Ward linkage (same as dendrogram)\n",
        "    labels = AgglomerativeClustering(n_clusters=k, linkage=\"ward\").fit_predict(X_scaled)\n",
        "\n",
        "    # Silhouette: +1 = dense & well‑separated, 0 = overlapping, −1 = wrong clustering\n",
        "    score = silhouette_score(X_scaled, labels)\n",
        "    sil_scores.append(score)\n",
        "\n",
        "# Plot the curve\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(list(k_range), sil_scores, marker=\"o\")\n",
        "plt.xticks(list(k_range))\n",
        "plt.xlabel(\"Number of Clusters (k)\")\n",
        "plt.ylabel(\"Average Silhouette Score\")\n",
        "plt.title(\"Silhouette Analysis for Agglomerative (Ward) Clustering\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Optional: print best k\n",
        "best_k = k_range[np.argmax(sil_scores)]\n",
        "print(f\"Best k by silhouette: {best_k}  (score={max(sil_scores):.3f})\")"
      ],
      "metadata": {
        "id": "mdFC94YJl_zX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}